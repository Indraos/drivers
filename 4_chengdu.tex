\chapter{The Value of Information}\label{chap:chengdu}
After our investigation into potential multi-homing frictions in a market, we give evidence here on the value of information to drivers. This is aligned with claims by companies that offer information services to drivers \tocite.

\section{Description of Data}
The DiDi KDD Challenge 2020, sponsored by DiDi Yuching, consisted of two challenge. An order dispatch challenge, and a driver repositioning challenge. We will work with data and submissions of the latter.

\subsection{Annotated Order Data}
We are given for November 2016 about %TODO: Find out concrete number
10 Million orders. An order consists of an origin-destination pair, a timestamp for beginning and end, an identifier for the driver that took the order, and a number of \emph{reward units}. As the data is not publicly available anymore, we are unable to provide replication data for the following analysis.

\subsection{Reinforcement Learning Challenge Leaderboard}
The KDD 2020 reinforcement learning challenge solves an optimal repositioning problem together with an optimal order dispatch problem. The problem is a Markov Decision Process, which is partially observable for the repositioning challenge. In Reinforcement Learning language, which we review in \autoref{app:math}.

The order dispatch problem is a reinforcement Learning Problem $(S, \mathcal A, T, R, f)$. The state is given locations of idle drivers as a list of orders. The actions are a (potentially partial) matching of available drivers to orders. All orders must be matched within a 2 second window, and otherwise fall through. 


We also use the leaderboard's reinforcement challenge leaderboard. It is reproduced from 
\subsection{Earnings Table}
We are using a publicly available table for earnings from 2021. In 2017, DiDi introduced two tiers of service for their drivers, Express 


%TODO: Visualize table.

%https://www.biendata.xyz/competition/kdd_didi/evaluation/
%https://pubs.aeaweb.org/doi/pdfplus/10.1257/jel.20181489
\section{Estimation}
\subsection{Model}
We assume that there is a constant $c$ such that 
\[
\operatorname{reward units} = c \operatorname{RMB}.
\]
The reason for this lies in the following proposition.

\subsection{Regression}\label{subsec:chengduregress}






\begin{table}
\centering
\begin{tabular}{lclc}
\toprule
\textbf{Dep. Variable:}    &  reward\_units   & \textbf{  R-squared:         } &     0.887   \\
\textbf{Model:}            &       OLS        & \textbf{  Adj. R-squared:    } &     0.887   \\
\textbf{Method:}           &  Least Squares   & \textbf{  F-statistic:       } &     1380.   \\
\textbf{Date:}             & Sun, 18 Jul 2021 & \textbf{  Prob (F-statistic):} &     0.00    \\
\textbf{Time:}             &     14:45:52     & \textbf{  Log-Likelihood:    } &   -2998.9   \\
\textbf{No. Observations:} &        2000      & \textbf{  AIC:               } &     6004.   \\
\textbf{Df Residuals:}     &        1997      & \textbf{  BIC:               } &     6021.   \\
\textbf{Df Model:}         &           2      & \textbf{                     } &             \\
\bottomrule
\end{tabular}
\begin{tabular}{lcccccc}
                   & \textbf{coef} & \textbf{std err} & \textbf{z} & \textbf{P$> |$z$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{Intercept} &      -0.1664  &        0.077     &    -2.155  &         0.031        &       -0.318    &       -0.015     \\
\textbf{distance}  &       0.3191  &        0.021     &    15.449  &         0.000        &        0.279    &        0.360     \\
\textbf{duration}  &       0.0635  &        0.007     &     9.645  &         0.000        &        0.051    &        0.076     \\
\bottomrule
\end{tabular}
\end{table}
\subsection{Checks}

\begin{table}
\centering
\begin{tabular}{lcccccc}
                                     & \textbf{coef} & \textbf{std err} & \textbf{z} & \textbf{P$> |$z$|$} & \textbf{[0.025} & \textbf{0.975]}  \\
\midrule
\textbf{Intercept}                   &      -0.2569  &        0.262     &    -0.981  &         0.326        &       -0.770    &        0.256     \\
\textbf{rush\_hour[T.True]}          &       0.0095  &        0.320     &     0.030  &         0.976        &       -0.618    &        0.637     \\
\textbf{distance}                    &       0.3318  &        0.047     &     7.113  &         0.000        &        0.240    &        0.423     \\
\textbf{rush\_hour[T.True]:distance} &      -0.0292  &        0.048     &    -0.602  &         0.547        &       -0.124    &        0.066     \\
\textbf{duration}                    &       0.0653  &        0.011     &     6.170  &         0.000        &        0.045    &        0.086     \\
\textbf{rush\_hour[T.True]:duration} &       0.0028  &        0.014     &     0.200  &         0.841        &       -0.024    &        0.030     \\
\bottomrule
\end{tabular}
%\caption{OLS Regression Results}
\end{table}

\section{Discussion}
