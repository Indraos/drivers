\chapter{Information Design}\label{chap:infodesign}
\begin{quote}
	The information design problem has
a literal interpretation: there
really is an information designer (or mediator, or sender) who can commit to provide extra information to players to serve her own
interests. While the commitment assumption may be problematic in many settings, it provides a useful benchmark.--\cite{Bergemann}
\end{quote}

%TODO: Incorporate this structure
%- Model 
%- Atomic Game
%- Cheap Talk Stage
%- BCE stage
%- Private vs. public information
%
%- Analysis
%
%- Private Information
%- Solution for Private Information Cheap Talk
%Private Information is desired
%- Solution for Private Information Info Design
%Babbling
%- Comparison
%
%- Public Information
%- Solution for Public Info Cheap Talk
%- Solution for Public Info Information Design
%- Comparison
%
%- Remedies
%
%- Commitment
%- Third Party Information Intermediaries
%- Repeated Game
%- Other sources of Commitment
%
%- Small group of targeted agents
%- Result
%- Third Party Interpretation
%- High-Scoring Agents Information
%
%- Conclusions


In this section, we study \emph{pure} information design for platform drivers. We refer to it as \emph{pure} as we study information provision while keeping the driver payoffs fixed. We show several limitations for the platform: Drivers, in equilibrium, ignore information if it cannot commit to not giving a particular driver some part of the information, it gives
\section{Model}
We consider a finite set of agents $i = 1, 2, \dots, n$. There are states of the world $\Theta$. We consider a basic game given by, for each player $i$ an action set $A_i$ and a utility function
\[
u_i \colon A \times \Theta \to \R
\]
where $A = A_1 \times \cdots \times A_n$ and a prior distribution $F \in \Delta(\Theta)$ which we assume has full support. We assume that this prior is shared by all players and the designer. $((A_i, u_i)_{i=1,2,\dots, n}, F)$ hence specifies a standard game. 

Our main model will consider $n=2$ drivers that simultaneously decide whether to drive to a part of a city (\enquote{go}) or to follow other business on or off the platform (\enquote{not go}), i.e. $A_1 = A_2 = \{\text{go}, \text{not go}\}$. The utility functions are given by the tables in \autoref{fig:twodrivers}. We assume that the prior is that with probability $p \in [0,1]$ demand is realized. This corresponds to an outside option for the drivers of $\sigma$ and a cost to go to the high-demand area of $\varepsilon$.

We call this game the \emph{basic game}. 

The information designer has a utility function
\[
v \colon A \times \Theta \to \R.
\] 
In our example, the information designer is a TNC. It will be an information designer, and will get utility $1$ if at least one driver is able to satisfy demand, otherwise a utility of $0$. 

The platform can design an \emph{information structure} $S$ consisting of, for each agent $i = 1, 2, \dots, n$ a type space $T_i$ and a type distribution $\pi \colon \Theta \to T$, where $T = T_1 \times \cdots \times T_n$, $S = (T, \pi)$.

The timeline of this model is
\begin{itemize}
	\item The information designer commits to an information structure $S = (T, \pi)$.
	\item The state of the world is realized.
	\item The players each receive their types $\pi_i(\theta)$.
	\item The agents select their action $a_i$.
	\item The payoffs are realized.
\end{itemize}
A revelation principle, which we do not prove, is that the messages that the information designer/platform needs to send, can be restricted to action recommendations
\[
	\sigma\colon\Theta \times T \to \Delta(A)
\]
such that the agent, given their information on $\Theta$ as given by their information, would like to follow the recommendation. For a full statement and proof of the revelation principle, compare \cite{Baskerville2011}. Mathematically, the remaining constraint of \emph{obedience} can be written as
\[
	\sum_{a_i, t_i, \theta} u_i((a_i, a_{-i}); \theta)\sigma((a_i,a_{-i}) | (t_i, t_{-i}), \theta) \pi((t_i, t_{-i}) | \theta) F(\theta) \ge \sum_{a_i, t_i, \theta} u_i((a_i', a_{-i}); \theta)\sigma((a_i,a_{-i}) | (t_i, t_{-i}), \theta) \pi((t_i, t_{-i}) | \theta) F(\theta)
\]
for any $a_i' \in A_i$. A profile of decision rules $\sigma$ that is obedient is called a Bayes Correlated Equilibrium (BCE). In our example of $n=2$ drivers, obedience means that it is optimal for drivers to follow the recommendation of the platform. 

The platform's utility is given by 
\begin{equation}
V(\sigma) = \sum_{a,t,\theta} v(a,\theta) \sigma(a| t, \theta) \pi(t | \theta) F(\theta).\label{eq:value}
\end{equation}
The platform's optimal information design is maximizing \eqref{eq:value} among all BCEs.

We make the assumption that getting a ride, even after driving to a high-demand area is better than the outside option, but the outside option is preferrable to to getting a ride with $\frac12$ probability, $1-\varepsilon \ge \sigma \ge \frac12-\varepsilon$.

\begin{prop}
An optimal information design is given by:
\[
	\sigma(0,\text{go}) = 
\]
and 
\[
	\sigma (1, \textbf{go}) = 
\]
\end{prop}
Conditional on the good state, this minimizes the correlation of 


\begin{proof}
	
\end{proof}


\begin{figure}
\centering
\begin{subfigure}{.48\linewidth}
\begin{tikzpicture}
\matrix[matrix of math nodes,every odd row/.style={align=right},every even row/.style={align=left},every node/.style={text width=1.5cm},row sep=0.2cm,column sep=0.2cm] (m) {
$\frac12-\varepsilon$&$\sigma$\\
$\frac12-\varepsilon$&$1-\varepsilon$\\
$1-\varepsilon$&$\sigma$\\
$\sigma$&$\sigma$\\
};
\draw (m.north east) rectangle (m.south west);
\draw (m.north) -- (m.south);
\draw (m.east) -- (m.west);
\coordinate (a) at ($(m.north west)!0.25!(m.north east)$);
\coordinate (b) at ($(m.north west)!0.75!(m.north east)$);
\node[above=5pt of a,anchor=base] {go};
\node[above=5pt of b,anchor=base] {not go};

\coordinate (c) at ($(m.north west)!0.25!(m.south west)$);
\coordinate (d) at ($(m.north west)!0.75!(m.south west)$);
\node[left=2pt of c,text width=1cm]  {go};
\node[left=2pt of d,text width=1cm]  {not go};

\node[above=18pt of m.north] (firm b) {Driver 2};
\node[left=1.6cm of m.west,rotate=90,align=center,anchor=center] {Driver 1};
\end{tikzpicture}
\caption{Demand, $\theta = 1$}
\end{subfigure}
\begin{subfigure}{.48\linewidth}
\begin{tikzpicture}
\matrix[matrix of math nodes,every odd row/.style={align=right},every even row/.style={align=left},every node/.style={text width=1.5cm},row sep=0.2cm,column sep=0.2cm] (m) {
$-\varepsilon$&$\sigma$\\
$-\varepsilon$&$-\varepsilon$\\
$-\varepsilon$&$\sigma$\\
$\sigma$&$\sigma$\\
};
\draw (m.north east) rectangle (m.south west);
\draw (m.north) -- (m.south);
\draw (m.east) -- (m.west);
\coordinate (a) at ($(m.north west)!0.25!(m.north east)$);
\coordinate (b) at ($(m.north west)!0.75!(m.north east)$);
\node[above=5pt of a,anchor=base] {go};
\node[above=5pt of b,anchor=base] {not go};

\coordinate (c) at ($(m.north west)!0.25!(m.south west)$);
\coordinate (d) at ($(m.north west)!0.75!(m.south west)$);
\node[left=2pt of c,text width=1cm]  {go};
\node[left=2pt of d,text width=1cm]  {not go};

\node[above=18pt of m.north] (firm b) {Driver 2};
\node[left=1.6cm of m.west,rotate=90,align=center,anchor=center] {Driver 1};
\end{tikzpicture}
\caption{No, $\theta = 0$}
\end{subfigure}
\caption{Payoff Matrix for the two-driver game.}\label{fig:twodrivers}
\end{figure}
We assume that the drivers best respond to the messages sent by the platform. In our first model, we assume that the platform can commit to a particular mapping from demand to messages, in the latter they cannot.


\subsection{Information Design}\label{subsec:infodesign}
We first study a setting where the platform can commit to an arbitrary mapping of demand $\theta$ to tuple of messages $(m_1(\theta), m_2 (\theta))$. Before stating our theorem, we go into public or private information.
\subsection{Public and Private Messages}
Some information is shown to all drivers, while other is shown only to a few drivers. We call messages \emph{public} if $m_1(\theta) = m_2(\theta)$ for $\theta = 0,1$ and all other messages \emph{private}. As is well-known in the information design literature \cite{Bergemann}, the game that agents play is one of \emph{strategic substitutes}, andp private information will increase the total utility for all players. In our case, this means, drivers. Our theorem adds that this is also the optimal choice of messages for the platform.
\begin{thm}\label{thm:commitment}
All maximizers of platform revenue are $m_1(\theta) = \theta$, 
\end{thm}


\subsection{Cheap Talk}\label{subsec:cheaptalk}
In cheap talk, the platform discloses some information to a driver, which, given the update, updates their behavior. More concretely, there is an abstract set of \emph{messages} $m \in \mathcal M$ that the platform can send. The players receive the message and play optimally. In particular, the timeline of the game is:
\begin{enumerate}
	\item The demand $\theta$ at the area is realized.
	\item The platform decides to send messages $(m_1, m_2)$ to the drivers.
	\item The drivers decide to drive or not drive to the area.
	\end{enumerate}
We solve for perfect Bayesian (signalling) equilibria of this game.
\begin{thm}\label{thm:commitment}
	In the cheap talk model, Perfect Bayesian equilibria have the following form:
	\begin{enumerate}
		\item If $\sigma < \frac12 - \varepsilon$ or $\sigma > 1-\varepsilon$, then the platform is indifferent between any message, the drivers will visit their dominant choice.
		\item If $\frac12 -\varepsilon \le \sigma  \le 1-\varepsilon$, the platform is indifferent between any message, and the drivers ignore the information. 
	\end{enumerate}
\end{thm}
We show a proof to this statement in \autoref{app:ommited}
If the general outside option is very low ($\sigma < \frac12 - \varepsilon$) or very high ($\sigma > 1 - \varepsilon$), drivers go to the area in hope to get a ride or stay away from it, respectively, even without demand information. The platform is indifferent between any demand information given that it won't influence the driver's decisions. This is an example where agents know that there is a high 

In the other cases, the platform cannot transmit any information. The 

In this environment, hence, if the not internalized cost from 

\section{Inefficiencies}
After analysing the predictions, we identify two sources of inefficiencies: a potential lack of commitment (a comparison between our cheap talk and the commitment solution) and a potential lack of being able to provide asymmetric information.
\subsection{Inefficiencies through lack of commitment}
\begin{prop}\label{cor:commitmentlack}
	The cheap talk version of the game has lower welfare. This statement is uniform: Both platform and driver surplus are lower in the cheap talk game.
\end{prop}
The statement shows that neither side benefits from limited commitment of the platform. The drivers have to rely on less information, and cannot trust the platform. The equilibrium is \enquote{babbling}. 

\subsection{Inefficiencies through public information}
Comparing our second two theorems, we find the following loss from public information.
\begin{cor}
In the commitment regime, only allowing public information reduces platform and driver surplus. In the cheap talk regime, this restriction increases welfare
\end{cor}
This result might look somewhat surprising.
\section{Discussion and Remedies}
Given the inefficiencies observed in the last section, some remedies for the market should be considered. We introduce two potential solutions to the platform's commitment problem, and one solution to the allocation problem. 
\subsection{Commitment via third parties}
A main driver of the inefficiencies in our model was that there is a conflict of incentives between the platform and the drivers. In this environment, if drivers \enquote{pay} the platform, there is not much. 
\subsection{Commitment via reputation}
A second opportunity for the platform to commit is via reputation. This assumes that the game of information provision studied in this section is repeated sufficiently often. 
\begin{thm}[\cite{Friedman1973}]
	In an infinitely repeated game with sufficiently patient agents, all individually rational payoffs can be achieved as a result of equilibrium play.
\end{thm}
This statement is allowed by agents playing a \enquote{punishment} equilibrium from the platform. It is unlikely in the setting of platform drivers that they can individually punish the platform, which, in return, does not incentivize the platform to give recommendations according to a commitment problem.
\subsection{Approximate Efficiency of Public Information to Few Drivers}
For our last statement, we will need a more general model. There are $n$ drivers, which learn a state $\theta \in \{0,1 , 2,\dots, n\}$. Drivers get a utility $1-\varepsilon$ if matched to a ride and they get a utility of $-\varepsilon$ if not matched. We assume that $n$ is large, and a small fraction of drivers can get a public message.
\begin{prop}
	Assume that drivers are 
\end{prop}